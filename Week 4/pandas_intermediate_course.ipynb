{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Pandas Techniques\n",
    "\n",
    "## Course Overview\n",
    "\n",
    "Building on the introduction, this notebook covers advanced Pandas techniques:\n",
    "- Advanced data manipulation\n",
    "- Time series analysis\n",
    "- Performance optimization\n",
    "- Advanced merging and joining\n",
    "- Data cleaning and preprocessing\n",
    "- Complex aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Advanced Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot Table:\n",
      "B         one     three       two\n",
      "A                                \n",
      "bar  0.505531 -0.175603  3.733282\n",
      "foo  1.095014       NaN  0.640933\n",
      "\n",
      "Melted DataFrame:\n",
      "     A      B variable     value\n",
      "0  foo    one        C  1.095014\n",
      "1  bar    one        C  0.505531\n",
      "2  foo    two        C -0.973256\n",
      "3  bar  three        C -0.175603\n",
      "4  foo    two        C  2.255122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>B</th>\n",
       "      <th>one</th>\n",
       "      <th>three</th>\n",
       "      <th>two</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bar</th>\n",
       "      <td>0.505531</td>\n",
       "      <td>-0.175603</td>\n",
       "      <td>3.733282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foo</th>\n",
       "      <td>1.095014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "B         one     three       two\n",
       "A                                \n",
       "bar  0.505531 -0.175603  3.733282\n",
       "foo  1.095014       NaN  0.640933"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating complex DataFrames\n",
    "df = pd.DataFrame({\n",
    "    'A': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar'],\n",
    "    'B': ['one', 'one', 'two', 'three', 'two', 'two'],\n",
    "    'C': np.random.randn(6),\n",
    "    'D': np.random.randn(6)\n",
    "})\n",
    "\n",
    "# Pivot table\n",
    "pivot = df.pivot_table(values='C', index='A', columns='B', aggfunc='mean')\n",
    "print(\"Pivot Table:\")\n",
    "print(pivot)\n",
    "\n",
    "# Melt transformation\n",
    "melted = df.melt(id_vars=['A', 'B'], value_vars=['C', 'D'])\n",
    "print(\"\\nMelted DataFrame:\")\n",
    "print(melted.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Means:\n",
      "2023-01-31   -0.098884\n",
      "2023-02-28   -0.051505\n",
      "2023-03-31   -0.079920\n",
      "2023-04-30    0.125409\n",
      "Freq: ME, dtype: float64\n",
      "\n",
      "7-Day Rolling Mean:\n",
      "2023-01-01   NaN\n",
      "2023-01-02   NaN\n",
      "2023-01-03   NaN\n",
      "2023-01-04   NaN\n",
      "2023-01-05   NaN\n",
      "Freq: D, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1835/997216924.py:6: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  daily_mean = ts.resample('M').mean()\n"
     ]
    }
   ],
   "source": [
    "# Generate time series data\n",
    "dates = pd.date_range('2023-01-01', periods=100, freq='D')\n",
    "ts = pd.Series(np.random.randn(100), index=dates)\n",
    "\n",
    "# Resampling\n",
    "daily_mean = ts.resample('M').mean()\n",
    "print(\"Monthly Means:\")\n",
    "print(daily_mean)\n",
    "\n",
    "# Rolling window calculations\n",
    "rolling_mean = ts.rolling(window=7).mean()\n",
    "print(\"\\n7-Day Rolling Mean:\")\n",
    "print(rolling_mean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.2 ms, sys: 12.3 ms, total: 50.5 ms\n",
      "Wall time: 50.5 ms\n",
      "CPU times: user 11.7 ms, sys: 0 ns, total: 11.7 ms\n",
      "Wall time: 11.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed eval>:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>-0.000204</td>\n",
       "      <td>-68.071703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-0.000278</td>\n",
       "      <td>-92.705273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.001111</td>\n",
       "      <td>370.046816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean         sum\n",
       "category                      \n",
       "A        -0.000204  -68.071703\n",
       "B        -0.000278  -92.705273\n",
       "C         0.001111  370.046816"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Large dataset generation\n",
    "large_df = pd.DataFrame({\n",
    "    'category': np.random.choice(['A', 'B', 'C'], size=1000000),\n",
    "    'value': np.random.randn(1000000)\n",
    "})\n",
    "\n",
    "# Efficient groupby\n",
    "%time large_df.groupby('category')['value'].agg(['mean', 'sum'])\n",
    "\n",
    "# Using categoricals for memory efficiency\n",
    "large_df['category'] = large_df['category'].astype('category')\n",
    "%time large_df.groupby('category')['value'].agg(['mean', 'sum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Merging and Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Join:\n",
      "  key  value1  value2\n",
      "0   B       2      20\n",
      "1   D       4      40\n",
      "\n",
      "Outer Join:\n",
      "  key  value1  value2\n",
      "0   A     1.0     NaN\n",
      "1   B     2.0    20.0\n",
      "2   C     3.0     NaN\n",
      "3   D     4.0    40.0\n",
      "4   E     NaN    50.0\n",
      "5   F     NaN    60.0\n"
     ]
    }
   ],
   "source": [
    "# Create sample DataFrames\n",
    "df1 = pd.DataFrame({\n",
    "    'key': ['A', 'B', 'C', 'D'],\n",
    "    'value1': [1, 2, 3, 4]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'key': ['B', 'D', 'E', 'F'],\n",
    "    'value2': [20, 40, 50, 60]\n",
    "})\n",
    "\n",
    "# Different types of joins\n",
    "inner_join = pd.merge(df1, df2, on='key', how='inner')\n",
    "outer_join = pd.merge(df1, df2, on='key', how='outer')\n",
    "\n",
    "print(\"Inner Join:\")\n",
    "print(inner_join)\n",
    "\n",
    "print(\"\\nOuter Join:\")\n",
    "print(outer_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame:\n",
      "          A        B          C\n",
      "0  1.000000        a 2023-01-01\n",
      "1  2.000000        b 2023-02-01\n",
      "2  2.333333        c        NaT\n",
      "3  4.000000  unknown 2023-04-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1835/4101935864.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_df['A'].fillna(cleaned_df['A'].mean(), inplace=True)\n",
      "/tmp/ipykernel_1835/4101935864.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_df['B'].fillna('unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame with missing and problematic data\n",
    "dirty_df = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4],\n",
    "    'B': ['a', 'b', 'c', None],\n",
    "    'C': ['2023-01-01', '2023-02-01', 'invalid', '2023-04-01']\n",
    "})\n",
    "\n",
    "# Handle missing values\n",
    "cleaned_df = dirty_df.copy()\n",
    "cleaned_df['A'].fillna(cleaned_df['A'].mean(), inplace=True)\n",
    "cleaned_df['B'].fillna('unknown', inplace=True)\n",
    "\n",
    "# Convert to datetime with error handling\n",
    "cleaned_df['C'] = pd.to_datetime(cleaned_df['C'], errors='coerce')\n",
    "\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Complex Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-level Aggregation:\n",
      "              value1       value2    \n",
      "                 sum  mean    max min\n",
      "group1 group2                        \n",
      "A      X          10  10.0      1   1\n",
      "       Y          20  20.0      2   2\n",
      "B      X          30  30.0      3   3\n",
      "       Y          40  40.0      4   4\n"
     ]
    }
   ],
   "source": [
    "# Create multi-level DataFrame\n",
    "multi_df = pd.DataFrame({\n",
    "    'group1': ['A', 'A', 'B', 'B'],\n",
    "    'group2': ['X', 'Y', 'X', 'Y'],\n",
    "    'value1': [10, 20, 30, 40],\n",
    "    'value2': [1, 2, 3, 4]\n",
    "})\n",
    "\n",
    "# Advanced groupby with multiple aggregations\n",
    "result = multi_df.groupby(['group1', 'group2']).agg({\n",
    "    'value1': ['sum', 'mean'],\n",
    "    'value2': ['max', 'min']\n",
    "})\n",
    "\n",
    "print(\"Multi-level Aggregation:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Indexing: `.loc` vs `.iloc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by label:\n",
      "Name    Bob\n",
      "Age      30\n",
      "City     SF\n",
      "Name: b, dtype: object\n",
      "\n",
      "Multiple label selection:\n",
      "      Name  Age      City\n",
      "a    Alice   25  New York\n",
      "c  Charlie   35   Chicago\n",
      "\n",
      "Conditional selection:\n",
      "      Name     City\n",
      "b      Bob       SF\n",
      "c  Charlie  Chicago\n",
      "d    David   Boston\n",
      "\n",
      ".iloc indexing:\n",
      "Name    Bob\n",
      "Age      30\n",
      "City     SF\n",
      "Name: b, dtype: object\n",
      "\n",
      "Slice with .iloc:\n",
      "      Name  Age\n",
      "b      Bob   30\n",
      "c  Charlie   35\n",
      "d    David   28\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with labeled index\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Age': [25, 30, 35, 28, 22],\n",
    "    'City': ['New York', 'SF', 'Chicago', 'Boston', 'LA']\n",
    "}, index=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "# .loc - Label-based indexing\n",
    "print(\"Selecting by label:\")\n",
    "print(df.loc['b'])  # Select row with label 'b'\n",
    "print(\"\\nMultiple label selection:\")\n",
    "print(df.loc[['a', 'c']])  # Select multiple rows\n",
    "\n",
    "# Conditional selection with .loc\n",
    "print(\"\\nConditional selection:\")\n",
    "print(df.loc[df['Age'] > 25, ['Name', 'City']])\n",
    "\n",
    "# .iloc - Integer-based indexing\n",
    "print(\"\\n.iloc indexing:\")\n",
    "print(df.iloc[1])  # Second row\n",
    "print(\"\\nSlice with .iloc:\")\n",
    "print(df.iloc[1:4, 0:2])  # Rows 1-3, first two columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Missing Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with missing values\n",
    "missing_df = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': [np.nan, 2, 3, np.nan, 5],\n",
    "    'C': ['apple', np.nan, 'cherry', 'date', np.nan]\n",
    "})\n",
    "\n",
    "# Detect missing values\n",
    "print(\"Missing value detection:\")\n",
    "print(missing_df.isna())  # Boolean mask of missing values\n",
    "print(\"\\nTotal missing values:\\n\", missing_df.isna().sum())\n",
    "\n",
    "# Handling missing values\n",
    "# Fill methods\n",
    "filled_mean = missing_df.fillna({\n",
    "    'A': missing_df['A'].mean(),\n",
    "    'B': 0,\n",
    "    'C': 'unknown'\n",
    "})\n",
    "\n",
    "# Advanced filling\n",
    "forward_filled = missing_df.fillna(method='ffill')  # Forward fill\n",
    "backward_filled = missing_df.fillna(method='bfill')  # Backward fill\n",
    "\n",
    "# Dropping missing values\n",
    "dropped = missing_df.dropna()  # Drop rows with ANY missing values\n",
    "dropped_all = missing_df.dropna(how='all')  # Drop only rows where ALL values are missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced Grouping and Pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create complex DataFrame for grouping\n",
    "sales_df = pd.DataFrame({\n",
    "    'Date': pd.date_range('2023-01-01', periods=12),\n",
    "    'Product': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B', 'A', 'B', 'C', 'A'],\n",
    "    'Region': ['North', 'South', 'East', 'West', 'North', 'South', \n",
    "               'East', 'West', 'North', 'South', 'East', 'West'],\n",
    "    'Sales': np.random.randint(100, 1000, 12)\n",
    "})\n",
    "\n",
    "# Multi-level grouping\n",
    "grouped = sales_df.groupby(['Product', 'Region'])\n",
    "\n",
    "# Complex aggregation\n",
    "agg_result = grouped['Sales'].agg([\n",
    "    ('total_sales', 'sum'),\n",
    "    ('avg_sales', 'mean'),\n",
    "    ('max_sales', 'max')\n",
    "])\n",
    "print(\"Multi-level Aggregation:\")\n",
    "print(agg_result)\n",
    "\n",
    "# Pivot table\n",
    "pivot_table = sales_df.pivot_table(\n",
    "    values='Sales', \n",
    "    index='Product', \n",
    "    columns='Region', \n",
    "    aggfunc='mean'\n",
    ")\n",
    "print(\"\\nPivot Table:\")\n",
    "print(pivot_table)\n",
    "\n",
    "# Advanced pivot with multiple aggregations\n",
    "multi_pivot = sales_df.pivot_table(\n",
    "    values='Sales', \n",
    "    index='Product', \n",
    "    columns='Region', \n",
    "    aggfunc=['mean', 'sum']\n",
    ")\n",
    "print(\"\\nMulti-aggregation Pivot:\")\n",
    "print(multi_pivot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
